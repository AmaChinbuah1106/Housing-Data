{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "056a5505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for project imported \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40047667",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'datahub\\\\housing.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8304\\1879986739.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Read dataset into notebook\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"datahub\\housing.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 932\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[1;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[1;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[0;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'datahub\\\\housing.csv'"
     ]
    }
   ],
   "source": [
    "#Read dataset into notebook \n",
    "df = pd.read_csv(\"datahub\\housing.csv\")\n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a514f3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Preparation stage\n",
    "# Using y = mx + c \n",
    "# Isolates the target column/columns of interest from the entire dataset \n",
    "X= df.drop(\"median_house_value\",axis =1)\n",
    "# Selects and displays the field of interest(\"median_house_value\")\n",
    "y=df[\"median_house_value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d4dd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displays the first 5 rows of the dataset\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d17219b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displays the first 5 rows of the dataset\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c55a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports model selection class from sklearn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f7b68d",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Splits the dataset into a train and test. \n",
    " #20% of the dataset will be used in the test state    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61349fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.8 * len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe19460",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.2*len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710187dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f0c11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f35b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0788fa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f7d111",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48534a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b7aa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d9bfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filling in missing values using sklearn \n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c742d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It fills in the missing values with the median \n",
    "imp = SimpleImputer(strategy=\"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2699080a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ocean_proximity was dropped from the train dataset because it is a string datatype\n",
    "num_X_train = X_train.drop(\"ocean_proximity\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82474d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90ec25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding total counts of missing values \n",
    "num_X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8c9451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It scans through the dataset and finds out the missing value for each column \n",
    "# Fits learns form the dataset and figures out what the missing values are \n",
    "imp.fit(num_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55331ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tran_num_X_train = pd.DataFrame(imp.transform(num_X_train), columns=num_X_train.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b87952",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding total counts of missing values \n",
    "tran_num_X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf976dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba9dd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ocean_proximity was dropped from the test dataset because it is a string datatype\n",
    "num_X_test = X_test.drop(\"ocean_proximity\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bbe36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tran_num_X_test = pd.DataFrame(imp.transform(num_X_test), columns = num_X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e400cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "tran_num_X_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8bed10",
   "metadata": {},
   "source": [
    "### 1. Evaluating The Model on Test Data \n",
    "You have trained and evaluated your model using your training data. Now you will evaluate the model again using only the test data to check if the model is really performing as good as our training metrics have us believing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1725b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for project imported \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fd6f65e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'datahub\\\\housing.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8304\\2804882790.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Read dataset into notebook\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"datahub\\housing.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 932\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[1;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[1;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[0;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'datahub\\\\housing.csv'"
     ]
    }
   ],
   "source": [
    "#Read dataset into notebook \n",
    "df = pd.read_csv(\"datahub\\housing.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de89890",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Preparation stage\n",
    "# Using y = mx + c \n",
    "# Isolates the target column/columns of interest from the entire dataset \n",
    "#X= df.drop(\"median_house_value\",axis =1)\n",
    "# Selects and displays the field of interest(\"median_house_value\")\n",
    "#y=df[\"median_house_value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e15ea62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displays the first 5 rows of the dataset\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe32681d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displays the first 5 rows of the dataset\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e01d66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports model selection class from sklearn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fd56ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splits the dataset into a train and test. \n",
    " #20% of the dataset will be used in the test state    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8686b532",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.8 * len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0493d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.2 * len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd49e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b073e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns a count of rows and columns \n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83093dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns the top 5 rows of the dataset\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45266988",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fe177c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57aaf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns the count of missing values \n",
    "X_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083756e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns the count of missing values\n",
    "X_train.isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f546c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filling in missing values using sklearn \n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b92eb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It fills in the missing values with the median \n",
    "impute = SimpleImputer(strategy=\"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a1caf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ocean_proximity was dropped from the train dataset because it is a string datatype\n",
    "num_X_test = X_test.drop(\"ocean_proximity\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28e56fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8be50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding total counts of missing values \n",
    "num_X_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3f0e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It scans through the dataset and finds out the missing value for each column \n",
    "# Fits learns form the dataset and figures out what the missing values are \n",
    "impute.fit(num_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cdf8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replaces the null values with the median and it is passed to a dataframe \n",
    "tran_num_X_test = pd.DataFrame(impute.transform(num_X_test), columns=num_X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6221065",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding total counts of missing values \n",
    "tran_num_X_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21478889",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df33852",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drops the particular column in the dataset \n",
    "#ocean_proximity is a string value and the machine accepts a unified datatype \n",
    "num_X_train = X_train.drop(\"ocean_proximity\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d26493",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replaces the null values with the median and it is passed to a dataframe \n",
    "tran_num_X_train = pd.DataFrame(impute.transform(num_X_train), columns = num_X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea36c86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding total counts of missing values \n",
    "tran_num_X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ec7796",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4b8cf3",
   "metadata": {},
   "source": [
    "### Changing the categorical data to numerical data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8c09f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constructs a dataframe from the dataset using the column \"ocean_proximity\"\n",
    "pd.get_dummies(X[\"ocean_proximity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6aab33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports the OneHotEncoder class \n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d514ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the encoder finds the unique values per feature and transforms the data to a binary one-hot encoding.\n",
    "enc = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acabc22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "enc.fit(X_test[[\"ocean_proximity\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d14dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(enc.transform(X_test[[\"ocean_proximity\"]]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9906187d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68f30e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "encod = pd.DataFrame(enc.transform(X_test[[\"ocean_proximity\"]]).toarray(), columns=enc.get_feature_names_out([\"ocean_proximity\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c868d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=tran_num_X_test.join(encod)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be872553",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(encod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8317b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(enc.transform(X_test[[\"ocean_proximity\"]]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3990e2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868474f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"rooms_per_household\"]=test_df[\"total_rooms\"]/test_df[\"households\"]\n",
    "test_df[\"bedrooms_per_room\"]=test_df[\"total_bedrooms\"]/test_df[\"total_rooms\"]\n",
    "test_df[\"population_per_household\"]=test_df[\"population\"]/test_df[\"households\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3b4e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f994c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df.corr()\n",
    "corr_matrix[\"median_house_value\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64599151",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels=df[\"median_house_value\"].copy()\n",
    "test = df.drop(\"median_house_value\",axis=1)\n",
    "test_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5cf3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c9252e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "num_pipeline=Pipeline([('imputer',SimpleImputer(strategy=\"median\")),(\"std_scaler\", StandardScaler())])\n",
    "test_num_tr=num_pipeline.fit_transform(num_X_test)\n",
    "test_num_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9de707f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "num_attribute = list(num_X_test)\n",
    "cat_attribute =[\"ocean_proximity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277bc1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline= ColumnTransformer ([(\"num\",num_pipeline,num_attribute),(\"cat\",OneHotEncoder(),cat_attribute)])\n",
    "test_prepared = full_pipeline.fit_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fc5822",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prepared.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5616e942",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "X = [[0., 0.], [1., 1.]]\n",
    "y = [0, 1]\n",
    "clf = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=5)\n",
    "clf.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825665fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_reg = LinearRegression() \n",
    "Sto_reg.fit(test_prepared, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353b6dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_data = test.iloc[:5]\n",
    "some_labels=test_labels.iloc[:5]\n",
    "# transform / prepare some data\n",
    "some_data_prepared = full_pipeline.transform(some_data)\n",
    "# make predictions\n",
    "print(\"Predictions:\", lin_reg.predict(some_data_prepared))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aff6485",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Labels:\",list(some_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bb8d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error \n",
    "test_predictions = lin_reg.predict(test_prepared)\n",
    "lin_mse=mean_squared_error(test_labels, test_predictions)\n",
    "lin_rmse=np.sqrt(lin_mse)\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858c546b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor \n",
    "tree_reg=DecisionTreeRegressor()\n",
    "tree_reg.fit(test_prepared, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f098522d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = tree_reg.predict(test_prepared)\n",
    "tree_mse=mean_squared_error(test_labels, test_predictions)\n",
    "tree_rmse=np.sqrt(tree_mse)\n",
    "tree_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82de86ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores=cross_val_score(tree_reg, test_prepared, test_labels,scoring=\"neg_mean_squared_error\", cv=10)\n",
    "tree_rmse_scores=np.sqrt(-scores)\n",
    "tree_rmse_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a700019",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "display_scores(tree_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb57ab8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_scores=cross_val_score(lin_reg, test_prepared,test_labels,scoring=\"neg_mean_squared_error\", cv=10)\n",
    "lin_rmse_scores=np.sqrt(-lin_scores)\n",
    "display_scores(lin_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7726388",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest_reg=RandomForestRegressor()\n",
    "forest_reg.fit(test_prepared, test_labels)\n",
    "test_predictions=forest_reg.predict(test_prepared)\n",
    "forest_mse=mean_squared_error(test_labels, test_predictions)\n",
    "forest_rmse=np.sqrt(tree_mse)\n",
    "forest_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7e4429",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_scores = cross_val_score(forest_reg,test_prepared,test_labels,scoring=\"neg_mean_squared_error\",cv=10)\n",
    "forest_rmse_scores = np.sqrt(-forest_scores)\n",
    "display_scores(forest_rmse_score)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac65bdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor \n",
    "forest_reg = RandomForestRegressor()\n",
    "forest_reg.fit(test_prepared, test_labels)\n",
    "test_predictions=forest_reg.predict(test_prepared)\n",
    "forest_mse=mean_squared_error(test_labels, test_predictions)\n",
    "forest_rmse=np.sqrt(tree_mse)\n",
    "forest_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e2a0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_scores=cross_val_score(forest_reg, test_prepared,test_labels,scoring=\"neg_mean_squared_error\", cv=10)\n",
    "forest_rmse_scores=np.sqrt(-forest_scores)\n",
    "display_scores(forest_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18cc0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "param_grid = [ {'n_estimators':[3,10,30],'max_features': [2,4,6,8]},{'bootstrap': [False],'n_estimators': [3,10],'max_features': [2,3,4]},]\n",
    "forest_reg = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(forest_reg, param_grid,cv=5,scoring='neg_mean_squared_error',return_train_score=True)\n",
    "grid_search.fit(test_prepared, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701fc288",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e859b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e503ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres=grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9af7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_\n",
    "# our result {'max_features': 8, 'n_estimators': 30}\n",
    "# Since 8 and 30 are the maximum values that were evaluated, you should␣↪probably try searching again with higher values, since the score may␣↪continue to improve.[52]:{'max_features': 8, 'n_estimators': 30}You can also get the best estimator directly:[53]:grid_search.best_estimator_36\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ae3f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle #from sklearn.externals import joblib \n",
    "filename='forest_housing_model.pkl'\n",
    "#joblib.dump(grid_search.best_estimator_,filename)\n",
    "filename='forest_housing_model.sav',pickle.dump(grid_search.best_estimator_,open(filename,'wb'))\n",
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fe3878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want re-load the model you can use the following code:\n",
    "model = pickle.load(open('forest_housing_model.pkl','rb'))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f3d1d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca008be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
